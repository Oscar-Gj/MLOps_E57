# CONFIGURACI√ìN GLOBAL DEL PROYECTO - SOUTH GERMAN CREDIT G57

Archivo: **params.yaml**  
Prop√≥sito:  
Define todos los par√°metros del pipeline MLOps del proyecto *South German Credit G57*.  
Centraliza la configuraci√≥n de datos, limpieza, preprocesamiento, modelado y evaluaci√≥n. Este archivo permite mantener la reproducibilidad y flexibilidad en cada fase del flujo.

-------------------------------------------------------------
OBJETIVO GENERAL
-------------------------------------------------------------
Servir como √∫nico punto de configuraci√≥n del pipeline completo:
    - Fase 1: Limpieza y validaci√≥n de datos
    - Fase 2: Construcci√≥n del pipeline (preprocesamiento)
    - Fase 3: Entrenamiento de modelos y registro en MLflow
    - Fase 4: Evaluaci√≥n y generaci√≥n de reportes

Cualquier cambio en los par√°metros de entrenamiento o datos puede realizarse
desde este archivo sin modificar el c√≥digo Python, promoviendo buenas pr√°cticas
de ingenier√≠a MLOps.

-------------------------------------------------------------
ESTRUCTURA GENERAL
-------------------------------------------------------------
1. base              ‚Üí Par√°metros generales y columna objetivo.
2. data              ‚Üí Rutas de acceso a los datasets (raw, processed, train, test).
3. data_cleaning     ‚Üí Reglas de limpieza, tratamiento de outliers y rare values.
4. preprocessing     ‚Üí Definici√≥n de features num√©ricos, categ√≥ricos y ordinales.
5. grid_search       ‚Üí Configuraci√≥n de la b√∫squeda de hiperpar√°metros (CV).
6. training          ‚Üí Modelos, t√©cnicas de muestreo y grids de par√°metros.
7. mlflow            ‚Üí Conexi√≥n local o cloud (seguimiento de experimentos).
8. reports           ‚Üí Rutas y configuraci√≥n de salida de m√©tricas y visualizaciones.

-------------------------------------------------------------
MODO DE EJECUCI√ìN
-------------------------------------------------------------
Este archivo es le√≠do directamente por `main.py` a trav√©s de:
    config = yaml.safe_load(open("params.yaml", "r"))

Ejemplo de ejecuci√≥n local:
    python -m south_german_credit_g57.main --config ../params.yaml --full-eval

Ejemplo de ejecuci√≥n en Cloud (MLflow remoto):
    python -m south_german_credit_g57.main --config ../params.yaml --full-eval

-------------------------------------------------------------
CONFIGURACI√ìN CLOUD
-------------------------------------------------------------
Si el modo seleccionado es "cloud", el experimento ser√° registrado en un
servidor remoto de MLflow desplegado en Google Cloud Run o Vertex AI.

Antes de ejecutar en este modo:
    1Ô∏è‚É£ Solicitar acceso al **administrador del entorno Cloud**.
    2Ô∏è‚É£ Tener credenciales activas de Google Cloud.
    3Ô∏è‚É£ Autenticarse en el proyecto correspondiente:
         gcloud auth login
         gcloud config set project laboratorio1-447417
    4Ô∏è‚É£ Verificar la URI en esta secci√≥n:

        mlflow:
          mode: "cloud"
          tracking_uri: "https://mlflow-super-g57-137680020436.us-central1.run.app"
          experiment_name: "Experimento-Conexi√≥n-MLFlow-Grupo57"

‚ö†Ô∏è Si el usuario no tiene permisos, el sistema devolver√° errores como:
   "The caller does not have permission" o "Access denied".

-------------------------------------------------------------
DETALLES DE CADA SECCI√ìN
-------------------------------------------------------------
üîπ base:
    - Define el seed (`random_state`) y la variable objetivo (`target_col`).
    - Garantiza consistencia entre fases (train/test split y modelado).

üîπ data:
    - Rutas absolutas o relativas de los datasets.
    - Las rutas pueden adaptarse al entorno local o al entorno Cloud Storage.

üîπ data_cleaning:
    - Define columnas a renombrar, eliminar o imputar.
    - Controla valores at√≠picos (`outlier_cols`) y categor√≠as raras (`rare_cols`).
    - Permite ajustar la proporci√≥n de test (`test_size`).

üîπ preprocessing:
    - Separa las features por tipo: num√©ricas, nominales y ordinales.
    - Define estrategias de imputaci√≥n por tipo de variable.
    - Compatible con Scikit-Learn `ColumnTransformer`.

üîπ grid_search:
    - Configura la validaci√≥n cruzada (CV y repeticiones).
    - Define la m√©trica principal de optimizaci√≥n (ej. ROC AUC).
    - Permite paralelizar en todos los cores disponibles (`n_jobs: -1`).

üîπ training:
    - Lista los modelos a entrenar (LogisticRegression, RandomForest, XGBoost, etc.).
    - Cada modelo define su `param_grid` y t√©cnica de balanceo (SMOTE, NearMiss).
    - Los par√°metros se aplican autom√°ticamente desde `train_model_pip.py`.

üîπ mlflow:
    - Determina si se ejecuta en modo local o cloud.
    - `experiment_name` y `tracking_uri` son usados para el registro de runs.
    - `evaluation_experiment_name` controla el registro de m√©tricas finales.

üîπ reports:
    - Carpeta de salida donde se guardan las gr√°ficas y reportes generados.
    - Compatible con los artefactos de MLflow (plots, .txt, .png, .html).

"""



# MAIN PIPELINE ORCHESTRATOR - SOUTH GERMAN CREDIT G57

"""
M√≥dulo principal encargado de orquestar todas las fases del pipeline MLOps
del proyecto *South German Credit G57*. Coordina la ejecuci√≥n completa del flujo
de Machine Learning bajo un enfoque reproducible, modular y automatizado, tanto
en entornos locales como en la nube (Cloud).

-------------------------------------------------------------
OBJETIVO GENERAL
-------------------------------------------------------------
Automatizar el ciclo de vida del modelo de cr√©dito:
    1. Limpieza y validaci√≥n de datos
    2. Construcci√≥n y entrenamiento del pipeline
    3. Evaluaci√≥n y registro de m√©tricas (MLflow)
    4. Evaluaci√≥n extendida (opcional, controlada por flags)

Incluye adem√°s la verificaci√≥n de dependencias (requirements.txt)
y su instalaci√≥n autom√°tica solo la primera vez.

-------------------------------------------------------------
ARQUITECTURA DEL PIPELINE
-------------------------------------------------------------
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  clean_data.py   ‚îÇ  ‚Üí Limpieza, imputaci√≥n y validaci√≥n de datos
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
 metrics.py  ‚óÑ‚îÄ‚îÄ main.py ‚îÄ‚îÄ‚îÄ‚ñ∫ pipeline.py
                     ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ train_model_pip ‚îÇ  ‚Üí Entrenamiento, validaci√≥n y registro en MLflow
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                 logger.py

-------------------------------------------------------------
MODOS DE EJECUCI√ìN
-------------------------------------------------------------
**1Ô∏è‚É£ Ejecuci√≥n local (por defecto):**
Guarda experimentos y modelos dentro del proyecto, bajo la carpeta:
    ./mlruns

Ejemplo:
    python -m south_german_credit_g57.main --config ../params.yaml --full-eval

**2Ô∏è‚É£ Ejecuci√≥n en entorno Cloud (GCP / MLflow remoto):**
Permite registrar los experimentos, m√©tricas y modelos directamente
en un servidor remoto (por ejemplo, MLflow desplegado en Google Cloud Run).

Antes de usar este modo, debes:
    - Solicitar acceso al administrador del entorno Cloud.
    - Tener credenciales activas de Google Cloud (cuenta @tec.mx o institucional).
    - Estar autenticado en el proyecto autorizado de GCP con el comando:

        gcloud auth login
        gcloud config set project <ID_PROYECTO_AUTORIZADO>

    - Verificar que el `tracking_uri` en `params.yaml` apunte a la URL del servidor MLflow remoto:

        mlflow:
          tracking_uri: "https://mlflow-super-g57-137680020436.us-central1.run.app"
          experiment_name: "Experimento-Conexi√≥n-MLFlow-Grupo57"

Ejemplo de ejecuci√≥n en modo Cloud:
    python -m south_german_credit_g57.main --config ../params.yaml --full-eval

‚ö†Ô∏è Importante:
El acceso remoto est√° restringido. Si el usuario no tiene permisos,
recibir√° un error de tipo "Permission denied" o "Caller does not have permission".
Debe solicitar autorizaci√≥n al **Administrador del Cloud del proyecto** antes de reintentar.

-------------------------------------------------------------
REQUERIMIENTOS
-------------------------------------------------------------
- Python 3.12 o 3.13
- Entorno virtual activado (p. ej. `jarvis`)
- Archivo de configuraci√≥n `params.yaml`
- Archivo de dependencias `requirements.txt` actualizado
- Acceso autorizado al servidor MLflow (para modo Cloud)
- Conectividad estable (si se ejecuta remotamente)

-------------------------------------------------------------
FLAGS DISPONIBLES
-------------------------------------------------------------
--config       ‚Üí Ruta al archivo YAML de configuraci√≥n.
--skip-clean   ‚Üí Omitir la fase de limpieza de datos.
--skip-train   ‚Üí Omitir el entrenamiento del modelo.
--skip-eval    ‚Üí Omitir la evaluaci√≥n final.
--full-eval    ‚Üí Ejecuta la evaluaci√≥n extendida al final del pipeline.

Ejemplo completo:
    python -m south_german_credit_g57.main --config ../params.yaml --full-eval

-------------------------------------------------------------
RESULTADOS Y SALIDAS
-------------------------------------------------------------
‚úî Datos procesados ‚Üí data/processed/
‚úî Modelos entrenados ‚Üí models/
‚úî M√©tricas ‚Üí reports/metrics/
‚úî Experimentos MLflow ‚Üí mlruns/ o servidor remoto (Cloud)
‚úî Logs ‚Üí logs/YYYY-MM-DD.log

"""



# Pruebas (Testing)

Este proyecto utiliza `pytest` para asegurar la calidad, correctitud y robustez del c√≥digo en todas las fases del pipeline de MLOps.

## 1. Configuraci√≥n del Entorno de Pruebas

Antes de ejecutar las pruebas, aseg√∫rate de tener el entorno virtual activado y las dependencias principales instaladas:
```bash
pip install -r requirements.txt
```

Unicamente si deseas generar un reporte con formato HTML, instala la dependencia `pytest-cov`:
```bash
pip install pytest-cov
```

## 2. Ejecuci√≥n de Pruebas

Todas las pruebas se encuentran en el directorio `Proyecto_south_german_credit_g57/tests/`.

### Ejecuci√≥n Completa (Modo Detallado)

Para ejecutar el conjunto completo de pruebas (unitarias y de integraci√≥n) y ver un desglose detallado de cada test, usa el comando `pytest` con el flag `-v` (verbose):
```bash
pytest -v
```

### Ejecuci√≥n R√°pida (Modo Silencioso)

Para cumplir con los requisitos del proyecto (T3), puedes ejecutar las pruebas en "modo silencioso" (`-q` / `quiet`). Este comando solo mostrar√° el resultado final (ej. `25 passed, 3 skipped in 140s`), lo cual es ideal para logs limpios o flujos de CI/CD.

Ejecuta este comando desde la ra√≠z del proyecto:
```bash
pytest -q
```

## 3. Cobertura de Pruebas (Opcional pero recomendado)

Para generar un reporte de "cobertura" (qu√© porcentaje de tu c√≥digo fuente est√° cubierto por las pruebas), puedes usar `pytest-cov`.
```bash
# Ejecuta las pruebas y calcula la cobertura para la carpeta 'src'
pytest --cov=src
```

Para un reporte visual detallado en HTML:
```bash
# Genera un reporte HTML
pytest --cov=src --cov-report=html
```

Esto crear√° una carpeta `htmlcov/`. Abre el archivo `htmlcov/index.html` en tu navegador para ver l√≠nea por l√≠nea qu√© c√≥digo fue probado y cu√°l no.

## 4. Estrategia de Pruebas Implementada

Se han implementado dos niveles de pruebas:

### Pruebas Unitarias (`tests/unit/`)

* **`test_preprocessing.py`**: Valida la l√≥gica de `clean_data.py`.
* **`test_training.py`**: Valida la l√≥gica de construcci√≥n de `train_model_pip.py` (creaci√≥n de pipelines, manejo de samplers, etc.).
* **`test_metrics.py`**: Valida que el `metrics_module.py` calcule correctamente m√©tricas clave (Accuracy, Precision, F1, ROC-AUC) usando casos de prueba definidos.

### Pruebas de Integraci√≥n (`tests/integration/`)

* **`test_main_pipeline.py`**: Valida el flujo end-to-end del orquestador `main.py`. Esta prueba ejecuta el pipeline completo (Clean ‚Üí Train) usando datos de prueba (`tests/fixtures/`) y una configuraci√≥n temporal (`tests/integration/test_params.yaml`).
* Utiliza `pytest-mock` para simular fallos de servicios externos (como `mlflow`), asegurando que la l√≥gica de fallback (guardado local del modelo) funcione correctamente.

### Configuraci√≥n (`pytest.ini`)

* Se ha configurado `pytest.ini` para a√±adir `src` al `PYTHONPATH` (evitando errores de importaci√≥n) y para suprimir warnings informativos conocidos de `sklearn` y `mlflow`, resultando en una salida de pruebas limpia.

# ü§ñ Simulador de Riesgo Crediticio (MLOps G57)

Este proyecto implementa una aplicaci√≥n web completa para la predicci√≥n de riesgo crediticio, siguiendo un pipeline de MLOps desde el entrenamiento del modelo hasta su despliegue en un contenedor unificado.

La aplicaci√≥n consta de dos componentes principales que se ejecutan en un solo contenedor Docker:

* **Backend (API de Inferencia):** Una API de FastAPI que sirve un modelo de Regresi√≥n Log√≠stica cargado directamente desde un Model Registry de MLflow.
* **Frontend (Interfaz de Usuario):** Una aplicaci√≥n web interactiva de Streamlit que consume la API de FastAPI, permitiendo a los usuarios ingresar datos en un formulario amigable y recibir una predicci√≥n de riesgo.

---

## üöÄ Arquitectura de la Aplicaci√≥n

Esta aplicaci√≥n utiliza una arquitectura unificada dentro de un contenedor Docker, dise√±ada para ser port√°til y f√°cil de desplegar.

* **Contenedor Docker:** Act√∫a como el servidor principal.
* **start.sh:** Un script de inicio que lanza ambos servicios.
* **API (FastAPI):** Se ejecuta en el puerto 8000. Al iniciar, se conecta a la URI de MLflow (`https://mlflow-super-g57...`) y descarga el modelo registrado (`LogisticRegression_model@best`).
* **UI (Streamlit):** Se ejecuta en el puerto 8001. Cuando un usuario env√≠a el formulario, esta aplicaci√≥n realiza una petici√≥n POST al backend de FastAPI en `http://127.0.0.1:8000/predict`.

---

## üìã Caracter√≠sticas Principales

### API de Inferencia (Backend - FastAPI)

* **Endpoint /predict:** Recibe los 20 campos del formulario como un JSON, los convierte a un DataFrame de pandas y los pasa al modelo de MLflow.
* **Auto-documentaci√≥n:** La API est√° completamente documentada con Swagger.
* **Validaci√≥n de Datos:** Utiliza Pydantic para asegurar que los tipos de datos enviados a la API sean correctos (`float`).
* **Modelo desde MLflow:** Carga el modelo directamente desde el Model Registry de MLflow, asegurando que siempre se utilice la versi√≥n designada (`best`).

### Interfaz de Usuario (Frontend - Streamlit)

* **Formulario Amigable:** Traduce los 20 campos t√©cnicos del modelo (ej. `credit_history`) a preguntas en espa√±ol (ej. "Historial Crediticio") usando men√∫s desplegables y sliders.
* **Visualizaci√≥n de Resultados:** Muestra la predicci√≥n final ("Riesgo Alto" / "Riesgo Bajo") con un indicador de confianza y una barra de progreso.
* **Interactivo:** Permite a los usuarios ajustar los valores y ver el impacto en la predicci√≥n.

---

## üõ†Ô∏è Prerrequisitos

Para ejecutar este proyecto, solo necesitas tener instalado y en ejecuci√≥n:

* Docker
* Git (para clonar el repositorio)

---

## ‚ö° Gu√≠a de Despliegue R√°pido (Local)

Sigue estos pasos para construir y ejecutar la aplicaci√≥n en tu m√°quina local.

### 1. Clonar el Repositorio

```
git clone https://github.com/Oscar-Gj/MLOps_E57.git
cd MLOps_E57
```

*(Nota: Reemplaza la URL si es diferente)*

### 2. Dar Permisos de Ejecuci√≥n (Solo Linux/Mac)

Este paso es crucial para permitir que Docker ejecute el script de inicio.

```
chmod +x start.sh
```

*(Si est√°s en Windows, ejecuta este comando usando Git Bash)*

### 3. Construir la Imagen de Docker

Este comando leer√° el Dockerfile, instalar√° las dependencias de `requirements.txt` (FastAPI, Streamlit, MLflow, etc.) y empaquetar√° tu aplicaci√≥n.

```
docker build -t app-credito-g57:latest .
```

*(No olvides el "." al final)*

### 4. Ejecutar el Contenedor

Este comando inicia el contenedor y expone los puertos de la API y de la interfaz de usuario a tu m√°quina local.

```
docker run -p 8000:8000 -p 8001:8001 app-credito-g57:latest
```

---

## üñ•Ô∏è C√≥mo Usar la Aplicaci√≥n

Una vez que el contenedor est√© corriendo, tendr√°s acceso a los dos servicios:

### 1. Interfaz de Usuario (Streamlit)

Esta es la aplicaci√≥n principal para usuarios finales.
**Acceso:** [http://127.0.0.1:8001](http://127.0.0.1:8001)

**Uso:**

* Ver√°s un formulario con **20 campos**.
* Completa los campos usando los men√∫s desplegables y sliders.
* Haz clic en el bot√≥n **"Predecir Riesgo"**.
* El resultado aparecer√° en la parte inferior, mostrando la **predicci√≥n y la probabilidad**.

### 2. Documentaci√≥n de la API (Swagger)

Si eres un desarrollador y quieres consumir la API directamente (por ejemplo, desde Postman o un script de Python), puedes usar la documentaci√≥n de Swagger.
**Acceso:** [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

**Uso:**

* Ver√°s el endpoint `POST /predict`.
* √Åbrelo y haz clic en **"Try it out"**.
* Puedes usar el JSON de ejemplo (`schema_extra`) para enviar una petici√≥n de prueba.
* Haz clic en **"Execute"** para ver la respuesta JSON del modelo.

---

## üìÅ Estructura de Archivos (Servidor)

```
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # L√≥gica de la API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py  # L√≥gica de la Interfaz (Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ a57.png           # Logo para la interfaz
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile            # Receta para construir el contenedor
‚îú‚îÄ‚îÄ requirements.txt      # Dependencias de Python (FastAPI, Streamlit, MLflow)
‚îî‚îÄ‚îÄ start.sh              # Script para iniciar ambos servicios
```

-------------------------------------------------------------
AUTOR√çA Y CONTROL DE VERSIONES
-------------------------------------------------------------
Autor: Equipo 57 MLOps
Fecha: Noviembre 2025
Versi√≥n: 2.1
Compatibilidad: Python 3.12 / 3.13 | Windows, macOS ARM, Linux
-------------------------------------------------------------