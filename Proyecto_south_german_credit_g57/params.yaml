# -------------------------------------------------
# PARÁMETROS GLOBALES DEL PROYECTO
# -------------------------------------------------
base:
  random_state: 1
  target_col: 'credit_risk'

# -------------------------------------------------
# 1. RUTAS DE DATOS
# -------------------------------------------------
data:
  raw: "data/processed/02_df_data_preparation_01.parquet"
  processed: "data/processed/02_df_data_preparation_01.parquet"

# -------------------------------------------------
# 2. PARÁMETROS DE LIMPIEZA DE DATOS
# (Usado por el script en src/preprocessing/cleaner.py)
# -------------------------------------------------
data_cleaning:
  rename_cols:
    - 'status'
    - 'duration'
    - 'credit_history'
    - 'purpose'
    - 'amount'
    - 'savings'
    - 'employment_duration'
    - 'installment_rate'
    - 'personal_status_sex'
    - 'other_debtors'
    - 'present_residence'
    - 'property'
    - 'age'
    - 'other_installment_plans'
    - 'housing'
    - 'number_credits'
    - 'job'
    - 'people_liable'
    - 'telephone'
    - 'foreign_worker'
    - 'credit_risk'
   
  drop_cols:
   
  # Corrección de outliers y errores en variables numéricas
  outlier_caps:
    duration: 72
    age: 75
    amount: 25000

# -------------------------------------------------
# 3. DEFINICIÓN DE FEATURES
# (Usado por el script en src/preprocessing/pipeline.py)
# -------------------------------------------------
features:
  numeric:
    - 'duration'
    - 'amount'
    - 'age'
  
  ordinal:
    - 'employment_duration'
    - 'installment_rate'
    - 'present_residence'
    - 'property'
    - 'number_credits'
    - 'job'

  categorical:
    - 'status'
    - 'credit_history'
    - 'purpose'
    - 'savings'
    - 'people_liable'
    - 'personal_status_sex'
    - 'other_debtors'
    - 'other_installment_plans'
    - 'housing'
    - 'telephone'
    - 'foreign_worker'

# -------------------------------------------------
# 4. PARÁMETROS DE DIVISIÓN DE DATOS (SPLIT)
# -------------------------------------------------
preprocessing:
  test_size: 0.30
  random_state: 1 # Heredado de `base.random_state`

# -------------------------------------------------
# 5. PARÁMETROS DE EVALUACIÓN (CROSS-VALIDATION)
# -------------------------------------------------
evaluation:
  cv_splits: 5
  cv_repeats: 3
  cv_random_state: 5
  metrics: 
    - 'accuracy'
    - 'precision'
    - 'recall'
    - 'f1'
    - 'roc_auc'
    - 'geometric_mean_score' # Esta se añadiría con make_scorer en el script

# -------------------------------------------------
# 6. CONFIGURACIÓN DE EXPERIMENTOS
# (Leído por src/training/train.py para iterar)
# -------------------------------------------------
experiments:
  
  logistic_regression:
    name: "Regresión_Logística"
    resampler: "SMOTE"
    resampler_params:
      random_state: 1
    model_params:
      penalty: 'l2'
      C: 0.1
      max_iter: 5000
      solver: 'saga'
      random_state: 1

  knn:
    name: "KNN"
    resampler: "NearMiss"
    resampler_params:
      version: 2
    model_params:
      n_neighbors: 25
      weights: 'uniform'
      metric: 'manhattan'
      p: 1
      algorithm: 'auto'

  dtree:
    name: "DTree"
    resampler: "SMOTETomek"
    resampler_params:
      random_state: 1
    model_params:
      criterion: "gini"
      max_depth: 20
      min_samples_split: 20
      min_samples_leaf: 5
      max_features: "sqrt"
      ccp_alpha: 0.01
      class_weight: "balanced"
      random_state: 1
      splitter: "best"

  rf:
    name: "RF"
    resampler: "SMOTEENN"
    resampler_params:
      random_state: 1
    model_params:
      n_estimators: 180
      max_depth: 6
      min_samples_split: 20
      min_samples_leaf: 25
      max_features: "log2"
      class_weight: "balanced"
      bootstrap: false
      random_state: 1

  xgboost:
    name: "XGBoost"
    resampler: "NearMiss"
    resampler_params:
      version: 3
    model_params:
      booster: 'gbtree'
      n_estimators: 200
      max_depth: 2
      learning_rate: 0.01
      subsample: 0.4
      colsample_bytree: 0.5
      reg_alpha: 1.0
      reg_lambda: 4.0
      objective: 'binary:logistic'
      tree_method: 'hist'
      random_state: 1
      n_jobs: -1

  mlp:
    name: "MLP"
    resampler: "SMOTETomek"
    resampler_params:
      random_state: 1
    model_params:
      hidden_layer_sizes: [8, 4] # YAML usa corchetes para listas
      activation: 'relu'
      solver: 'adam'
      max_iter: 1500
      alpha: 5
      learning_rate: 'adaptive'
      learning_rate_init: 0.007
      tol: 0.0001
      early_stopping: true
      n_iter_no_change: 15
      random_state: 1

  svc:
    name: "SVC"
    resampler: "SMOTE"
    resampler_params:
      sampling_strategy: 0.7
      random_state: 1
    model_params:
      kernel: 'rbf'
      C: 4
      gamma: 0.0025
      class_weight: 'balanced'
      probability: true
      random_state: 1


# -------------------------------------------------
# 7. PARÁMETROS DE GUARDADO DE MODELOS (MFLOW)
# -------------------------------------------------
mlflow:
  experiment_name: "Experimento-Conexión-MLFlow-Grupo57"
  tracking_uri: "https://mlflow-super-g57-137680020436.us-central1.run.app"
